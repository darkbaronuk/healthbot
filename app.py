import os
import sys
import gradio as gr
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
import shutil
import threading
import time
from queue import Queue

# Setup port cho Render
port = int(os.environ.get("PORT", 7860))
print(f"üîç ENV PORT: {os.environ.get('PORT', 'Not set')}")
print(f"üîç Using port: {port}")

# Load environment variables v·ªõi improved handling
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "").strip()

if not GOOGLE_API_KEY or GOOGLE_API_KEY == "":
    print("‚ùå GOOGLE_API_KEY ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p!")
    print("üìù Vui l√≤ng ki·ªÉm tra Environment Variables trong Render Dashboard")
    GOOGLE_API_KEY = "dummy"
else:
    print(f"‚úÖ GOOGLE_API_KEY loaded: {len(GOOGLE_API_KEY)} chars")
    if GOOGLE_API_KEY.startswith("AIza"):
        print("‚úÖ API Key format valid")
    else:
        print("‚ö†Ô∏è API Key format may be invalid (should start with 'AIza')")

print("üöÄ Kh·ªüi ƒë·ªông Healthbot cho H·ªôi Th·∫ßy thu·ªëc tr·∫ª Vi·ªát Nam...")

# Global variables
qa_chain = None
vector_db = None
initialization_status = "‚öôÔ∏è ƒêang kh·ªüi t·∫°o h·ªá th·ªëng..."
system_ready = False

def create_vector_db_with_timeout(chunks, embedding, timeout_seconds=120):
    """T·∫°o vector database v·ªõi timeout protection s·ª≠ d·ª•ng threading"""
    
    def worker(result_queue):
        try:
            start_time = time.time()
            print(f"üíæ Creating vector database with {len(chunks)} chunks...")
            
            vector_db = Chroma.from_documents(
                documents=chunks,
                embedding=embedding,
                persist_directory=None
            )
            
            elapsed = time.time() - start_time
            result_queue.put(('success', vector_db, elapsed))
            
        except Exception as e:
            result_queue.put(('error', str(e), 0))
    
    result_queue = Queue()
    worker_thread = threading.Thread(target=worker, args=(result_queue,), daemon=True)
    
    worker_thread.start()
    worker_thread.join(timeout=timeout_seconds)
    
    if worker_thread.is_alive():
        print("‚ö†Ô∏è Vector database creation timeout - trying emergency mode")
        return None, "timeout"
    
    try:
        result_type, result_data, elapsed = result_queue.get_nowait()
        if result_type == 'success':
            print(f"‚úÖ Vector database created in {elapsed:.1f}s")
            return result_data, 'success'
        else:
            print(f"‚ùå Vector database creation failed: {result_data}")
            return None, result_data
    except:
        return None, "queue_error"

def initialize_system():
    """Kh·ªüi t·∫°o h·ªá th·ªëng t·ªëi ∆∞u cho speed v√† stability"""
    global qa_chain, vector_db, initialization_status, system_ready
    
    print("\n‚ö° STARTING OPTIMIZED INITIALIZATION")
    print("=" * 50)
    
    try:
        # Step 1: Clean old data
        initialization_status = "üßπ Cleaning old data..."
        chroma_path = "chroma_db"
        if os.path.exists(chroma_path):
            shutil.rmtree(chroma_path)
            print("‚úÖ Old database cleaned")
        
        # Step 2: Load documents v·ªõi smart limiting
        initialization_status = "üìÇ Smart document loading..."
        docs = []
        data_folder = "data"
        
        if not os.path.exists(data_folder):
            print(f"‚ùå Folder {data_folder} not found")
            initialization_status = "‚ùå Data folder not found"
            return False
        
        pdf_files = [f for f in os.listdir(data_folder) if f.endswith(".pdf")]
        if not pdf_files:
            print("‚ùå No PDF files found")
            initialization_status = "‚ùå No PDF files found"
            return False
        
        # Smart limiting: Ch·ªâ load s·ªë l∆∞·ª£ng c·∫ßn thi·∫øt
        max_files = 3  # TƒÉng l√™n 3 files
        limited_files = pdf_files[:max_files]
        print(f"üìö Processing {len(limited_files)} files for optimal performance")
        
        initialization_status = f"üìÑ Loading {len(limited_files)} PDF files..."
        
        for i, file in enumerate(limited_files):
            print(f"üìÑ Loading ({i+1}/{len(limited_files)}): {file}")
            try:
                loader = PyPDFLoader(os.path.join(data_folder, file))
                file_docs = loader.load()
                
                # Smart page limiting
                max_pages = 20  # TƒÉng l√™n 20 pages per file
                if len(file_docs) > max_pages:
                    file_docs = file_docs[:max_pages]
                    print(f"   ‚ö° Using first {len(file_docs)} pages for speed")
                
                for doc in file_docs:
                    doc.metadata.update({
                        "source_file": file,
                        "page_count": len(file_docs),
                        "file_index": i
                    })
                
                docs.extend(file_docs)
                print(f"   ‚úÖ Success: {len(file_docs)} pages")
                
            except Exception as e:
                print(f"   ‚ùå Error loading {file}: {e}")
                continue
        
        if not docs:
            print("‚ùå No documents loaded successfully")
            initialization_status = "‚ùå Failed to load documents"
            return False
        
        print(f"‚úÖ Total loaded: {len(docs)} pages from {len(limited_files)} files")
        
        # Step 3: Optimized text splitting
        initialization_status = "‚úÇÔ∏è Smart text chunking..."
        print("‚úÇÔ∏è Creating optimized chunks...")
        
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,        # Balanced for quality vs speed
            chunk_overlap=200,      # Good overlap for context
            length_function=len,
            separators=["\n\n", "\n", ". ", "! ", "? ", " "]
        )
        
        chunks = splitter.split_documents(docs)
        
        # Progressive limiting based on chunk count
        if len(chunks) > 150:
            chunks = chunks[:150]
            print(f"‚ö° Limited to 150 chunks for optimal performance")
        elif len(chunks) > 100:
            chunks = chunks[:100]
            print(f"‚ö° Limited to 100 chunks for good performance")
        
        print(f"‚úÖ Using {len(chunks)} optimized chunks")
        
        # Step 4: Fast embedding model
        initialization_status = "üîß Loading embedding model..."
        print("üîß Loading fast embedding model...")
        
        try:
            embedding = HuggingFaceEmbeddings(
                model_name="sentence-transformers/all-MiniLM-L6-v2",  # Fastest model
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
            print("‚úÖ Fast embedding model loaded")
        except Exception as e:
            print(f"‚ùå Embedding model loading failed: {e}")
            initialization_status = f"‚ùå Embedding model error: {str(e)[:50]}..."
            return False
        
        # Step 5: Vector database v·ªõi timeout protection
        initialization_status = "üíæ Building vector database..."
        print(f"üíæ Building vector database ({len(chunks)} chunks)...")
        
        vector_db, status = create_vector_db_with_timeout(chunks, embedding, timeout_seconds=120)
        
        if status == 'timeout':
            # Emergency mode: Use fewer chunks
            emergency_chunks = chunks[:50]
            print(f"üö® Emergency mode: Using only {len(emergency_chunks)} chunks")
            
            try:
                vector_db = Chroma.from_documents(
                    documents=emergency_chunks,
                    embedding=embedding,
                    persist_directory=None
                )
                print("‚úÖ Emergency vector database created")
            except Exception as e:
                print(f"‚ùå Emergency vector DB also failed: {e}")
                initialization_status = f"‚ùå Vector DB failed: {str(e)[:50]}..."
                return False
                
        elif status != 'success':
            print(f"‚ùå Vector database creation failed: {status}")
            initialization_status = f"‚ùå Vector DB error: {status[:50]}..."
            return False
        
        # Step 6: API Key validation
        if GOOGLE_API_KEY == "dummy":
            print("‚ùå API Key not configured")
            initialization_status = "‚ùå API Key not configured"
            return False
        
        # Step 7: Setup AI system
        initialization_status = "ü§ñ Setting up AI system..."
        print("ü§ñ Setting up Gemini AI...")
        
        try:
            # Create optimized prompt
            prompt = PromptTemplate(
                template="""B·∫°n l√† tr·ª£ l√Ω y t·∫ø AI c·ªßa H·ªôi Th·∫ßy thu·ªëc tr·∫ª Vi·ªát Nam.

T√ÄI LI·ªÜU THAM KH·∫¢O:
{context}

C√ÇU H·ªéI: {question}

H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát ch√≠nh x√°c, chuy√™n nghi·ªáp
- D·ª±a ch·ªß y·∫øu v√†o th√¥ng tin t·ª´ t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p
- N·∫øu kh√¥ng c√≥ th√¥ng tin trong t√†i li·ªáu, n√≥i r√µ "Th√¥ng tin n√†y ch∆∞a c√≥ trong t√†i li·ªáu tham kh·∫£o"
- ƒê∆∞a ra l·ªùi khuy√™n y t·∫ø c·∫©n tr·ªçng v√† khuy·∫øn kh√≠ch tham kh·∫£o Th·∫ßy thu·ªëc chuy√™n khoa
- Lu√¥n nh·∫Øc nh·ªü t·∫ßm quan tr·ªçng c·ªßa vi·ªác kh√°m b·ªánh tr·ª±c ti·∫øp

TR·∫¢ L·ªúI:""",
                input_variables=["context", "question"]
            )
            
            # Create LLM
            llm = ChatGoogleGenerativeAI(
                model="gemini-1.5-pro",
                google_api_key=GOOGLE_API_KEY,
                temperature=0.2,
                max_output_tokens=6144
            )
            
            # Quick API test
            print("   Testing API connection...")
            test_response = llm.invoke("Test connection")
            print(f"   ‚úÖ API test successful: {test_response.content[:30]}...")
            
            # Create QA chain
            qa_chain = RetrievalQA.from_chain_type(
                llm=llm,
                retriever=vector_db.as_retriever(
                    search_kwargs={"k": 5}  # Return top 5 relevant chunks
                ),
                chain_type_kwargs={"prompt": prompt},
                return_source_documents=True
            )
            
            print("‚úÖ QA chain created successfully")
            
        except Exception as llm_error:
            print(f"‚ùå LLM setup failed: {llm_error}")
            error_msg = str(llm_error).lower()
            
            if "api key" in error_msg or "authentication" in error_msg:
                initialization_status = "‚ùå API Key authentication failed"
            elif "quota" in error_msg or "limit" in error_msg:
                initialization_status = "‚ùå API quota exceeded"
            elif "permission" in error_msg:
                initialization_status = "‚ùå API Key insufficient permissions"
            else:
                initialization_status = f"‚ùå LLM error: {str(llm_error)[:100]}..."
            
            return False
        
        # Success!
        print("\n" + "=" * 50)
        print("‚úÖ SYSTEM INITIALIZATION COMPLETED!")
        print(f"üìä Final stats:")
        print(f"   ‚Ä¢ Documents: {len(docs)} pages")
        print(f"   ‚Ä¢ Chunks: {len(chunks) if 'chunks' in locals() else 'N/A'}")
        print(f"   ‚Ä¢ Vector DB: {'‚úÖ Ready' if vector_db else '‚ùå Failed'}")
        print(f"   ‚Ä¢ AI Model: ‚úÖ Gemini 1.5 Pro")
        print("=" * 50)
        
        initialization_status = "‚úÖ S·∫µn s√†ng t∆∞ v·∫•n y t·∫ø!"
        system_ready = True
        return True
        
    except Exception as e:
        print(f"\n‚ùå INITIALIZATION FAILED: {e}")
        initialization_status = f"‚ùå Error: {str(e)[:100]}..."
        import traceback
        traceback.print_exc()
        return False

def ask_question(query):
    """X·ª≠ l√Ω c√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng v·ªõi comprehensive error handling"""
    global initialization_status, system_ready
    
    # Input validation
    if not query or not query.strip():
        return f"‚ùì Vui l√≤ng nh·∫≠p c√¢u h·ªèi.\n\nüìä Tr·∫°ng th√°i h·ªá th·ªëng: {initialization_status}"
    
    query = query.strip()
    
    if len(query) > 1000:
        return "üìù C√¢u h·ªèi qu√° d√†i. Vui l√≤ng r√∫t ng·∫Øn d∆∞·ªõi 1000 k√Ω t·ª± ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng tr·∫£ l·ªùi t·ªët nh·∫•t."
    
    # System readiness check
    if GOOGLE_API_KEY == "dummy":
        return """üîë L·ªói API Key - H·ªá th·ªëng ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh.

üìù H∆∞·ªõng d·∫´n kh·∫Øc ph·ª•c:
1. Truy c·∫≠p Render Dashboard
2. V√†o Settings ‚Üí Environment
3. Th√™m bi·∫øn GOOGLE_API_KEY v·ªõi gi√° tr·ªã t·ª´ Google AI Studio
4. Redeploy service sau khi c·∫≠p nh·∫≠t

üí° L∆∞u √Ω: API Key ph·∫£i b·∫Øt ƒë·∫ßu b·∫±ng 'AIza...'"""
    
    if not system_ready or not qa_chain:
        return f"""üîß H·ªá th·ªëng AI ch∆∞a s·∫µn s√†ng.

üìä Tr·∫°ng th√°i hi·ªán t·∫°i: {initialization_status}

üí° Th√¥ng tin:
‚Ä¢ Th·ªùi gian ∆∞·ªõc t√≠nh: 1-3 ph√∫t t√πy dung l∆∞·ª£ng d·ªØ li·ªáu
‚Ä¢ H·ªá th·ªëng ƒëang load v√† x·ª≠ l√Ω t√†i li·ªáu y t·∫ø
‚Ä¢ Vui l√≤ng ch·ªù v√† th·ª≠ l·∫°i sau

üîÑ Refresh trang v√† th·ª≠ l·∫°i sau √≠t ph√∫t..."""
    
    # Process question
    try:
        print(f"üîç Processing question: {query[:50]}{'...' if len(query) > 50 else ''}")
        
        # Validate qa_chain exists and is callable
        if not hasattr(qa_chain, 'invoke'):
            return "‚ùå H·ªá th·ªëng AI ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o ƒë√∫ng c√°ch. Vui l√≤ng refresh trang v√† th·ª≠ l·∫°i."
        
        # Execute query
        start_time = time.time()
        result = qa_chain.invoke({"query": query})
        processing_time = time.time() - start_time
        
        print(f"‚úÖ Question processed in {processing_time:.2f}s")
        
        # Extract and format answer
        answer = result.get("result", "Kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi.")
        
        # Add source information
        sources = result.get("source_documents", [])
        if sources:
            source_files = set()
            for doc in sources:
                if "source_file" in doc.metadata:
                    source_files.add(doc.metadata["source_file"])
            
            if source_files:
                answer += f"\n\nüìö **Ngu·ªìn t√†i li·ªáu tham kh·∫£o:** {', '.join(sorted(source_files))}"
        
        # Add medical disclaimer
        answer += f"\n\n---\n‚ö†Ô∏è **L∆∞u √Ω quan tr·ªçng:** Th√¥ng tin tr√™n ch·ªâ mang t√≠nh ch·∫•t tham kh·∫£o. H√£y tham kh·∫£o Th·∫ßy thu·ªëc chuy√™n khoa ƒë·ªÉ ƒë∆∞·ª£c ch·∫©n ƒëo√°n v√† ƒëi·ªÅu tr·ªã ch√≠nh x√°c. Trong tr∆∞·ªùng h·ª£p c·∫•p c·ª©u, h√£y g·ªçi 115."
        
        return answer
        
    except Exception as e:
        print(f"‚ùå Query processing error: {e}")
        error_msg = str(e).lower()
        
        # Specific error handling
        if "quota" in error_msg or "limit" in error_msg:
            return """‚ö†Ô∏è V∆∞·ª£t qu√° gi·ªõi h·∫°n API.

üìä Chi ti·∫øt:
‚Ä¢ Google AI Studio c√≥ gi·ªõi h·∫°n 15 requests/ph√∫t cho free tier
‚Ä¢ Vui l√≤ng ch·ªù 1-2 ph√∫t v√† th·ª≠ l·∫°i
‚Ä¢ Ho·∫∑c n√¢ng c·∫•p l√™n paid plan ƒë·ªÉ c√≥ quota cao h∆°n

‚è∞ Th·ª≠ l·∫°i sau: 2-3 ph√∫t"""
            
        elif "safety" in error_msg:
            return """‚ö†Ô∏è C√¢u h·ªèi ch·ª©a n·ªôi dung ƒë∆∞·ª£c ƒë√°nh gi√° l√† nh·∫°y c·∫£m.

üí° Khuy·∫øn ngh·ªã:
‚Ä¢ Di·ªÖn ƒë·∫°t l·∫°i c√¢u h·ªèi m·ªôt c√°ch r√µ r√†ng v√† tr·ª±c ti·∫øp h∆°n
‚Ä¢ T·∫≠p trung v√†o kh√≠a c·∫°nh y t·∫ø/s·ª©c kh·ªèe c·ª• th·ªÉ
‚Ä¢ Tr√°nh c√°c t·ª´ ng·ªØ c√≥ th·ªÉ g√¢y hi·ªÉu l·∫ßm

üîÑ Vui l√≤ng th·ª≠ ƒë·∫∑t c√¢u h·ªèi kh√°c."""
            
        elif "api" in error_msg or "authentication" in error_msg:
            return """üîë L·ªói x√°c th·ª±c API Key.

‚ùå Nguy√™n nh√¢n c√≥ th·ªÉ:
‚Ä¢ API Key kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng ho·∫∑c ƒë√£ h·∫øt h·∫°n
‚Ä¢ Billing account ch∆∞a ƒë∆∞·ª£c k√≠ch ho·∫°t trong Google Cloud
‚Ä¢ Service b·ªã v√¥ hi·ªáu h√≥a

üîó Ki·ªÉm tra t·∫°i: https://console.cloud.google.com/apis/credentials"""
            
        else:
            return f"""‚ùå C√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω c√¢u h·ªèi.

üîç Chi ti·∫øt l·ªói: {str(e)[:200]}{'...' if len(str(e)) > 200 else ''}

üí° C√°c b∆∞·ªõc kh·∫Øc ph·ª•c:
‚Ä¢ Th·ª≠ l·∫°i sau v√†i ph√∫t
‚Ä¢ ƒê·∫∑t c√¢u h·ªèi kh√°c ho·∫∑c di·ªÖn ƒë·∫°t l·∫°i
‚Ä¢ Ki·ªÉm tra k·∫øt n·ªëi internet
‚Ä¢ Li√™n h·ªá h·ªó tr·ª£ n·∫øu l·ªói ti·∫øp t·ª•c"""

def create_professional_interface():
    """T·∫°o giao di·ªán chuy√™n nghi·ªáp cho H·ªôi Th·∫ßy thu·ªëc tr·∫ª Vi·ªát Nam"""
    
    with gr.Blocks(
        theme=gr.themes.Soft(),
        css="""
        .gradio-container { 
            background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%); 
            font-family: 'Inter', 'Segoe UI', -apple-system, BlinkMacSystemFont, sans-serif;
        }
        .custom-header {
            background: linear-gradient(135deg, #1e40af 0%, #1d4ed8 100%);
            color: white;
            padding: 35px;
            border-radius: 20px;
            margin-bottom: 30px;
            box-shadow: 0 12px 40px rgba(29, 78, 216, 0.25);
        }
        .logo-section {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 25px;
            margin-bottom: 25px;
            flex-wrap: wrap;
        }
        .logo-circle {
            width: 85px;
            height: 85px;
            background: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            box-shadow: 0 8px 25px rgba(0,0,0,0.15);
            border: 3px solid rgba(255,255,255,0.3);
            padding: 8px;
        }
        .logo-circle img {
            width: 100%;
            height: 100%;
            object-fit: contain;
        }
        .info-card {
            background: white;
            padding: 25px;
            border-radius: 15px;
            box-shadow: 0 6px 20px rgba(0,0,0,0.08);
            border-left: 5px solid #1d4ed8;
            margin-bottom: 20px;
        }
        .stat-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin-top: 20px;
        }
        .stat-item {
            background: #f8fafc;
            padding: 12px;
            border-radius: 8px;
            text-align: center;
            border: 1px solid #e2e8f0;
            transition: all 0.3s ease;
        }
        .stat-item:hover {
            background: #e0f2fe;
            transform: translateY(-2px);
        }
        @media (max-width: 768px) {
            .logo-section { 
                flex-direction: column; 
                gap: 15px; 
            }
            .custom-header { 
                padding: 25px 20px; 
            }
        }
        """,
        title="üè• H·ªôi Th·∫ßy thu·ªëc tr·∫ª Vi·ªát Nam - AI Medical Assistant"
    ) as interface:
        
        # PROFESSIONAL HEADER v·ªõi logo v√† branding
        gr.HTML("""
        <div class="custom-header">
            <div class="logo-section">
                <div class="logo-circle">
                    <img src="http://thaythuoctre.vn/wp-content/uploads/2020/12/logo-ttt.png" 
                         alt="Logo H·ªôi Th·∫ßy thu·ªëc tr·∫ª Vi·ªát Nam"
                         onerror="this.style.display='none'; this.parentElement.innerHTML='üë®‚Äç‚öïÔ∏è';">
                </div>
                <div style="text-align: center;">
                    <h1 style="margin: 0; font-size: 32px; font-weight: 800; color: white; text-shadow: 2px 2px 6px rgba(0,0,0,0.3); letter-spacing: -0.5px;">
                        H·ªòI TH·∫¶Y THU·ªêC TR·∫∫ VI·ªÜT NAM
                    </h1>
                    <p style="margin: 10px 0 0 0; font-size: 18px; color: white; opacity: 0.95; font-weight: 400;">
                        ü§ñ Tr·ª£ l√Ω Y t·∫ø AI - T∆∞ v·∫•n s·ª©c kh·ªèe th√¥ng minh 24/7
                    </p>
                    <p style="margin: 8px 0 0 0; font-size: 14px; color: white; opacity: 0.9;">
                        ƒê∆∞·ª£c ph√°t tri·ªÉn b·ªüi c√°c Th·∫ßy thu·ªëc tr·∫ª Vi·ªát Nam
                    </p>
                </div>
            </div>
            
            <div style="background: rgba(255,255,255,0.15); padding: 20px; border-radius: 15px; border: 1px solid rgba(255,255,255,0.2); backdrop-filter: blur(10px);">
                <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; text-align: center;">
                    <div>
                        <div style="font-size: 24px; margin-bottom: 5px;">üåê</div>
                        <strong style="color: white;">Website ch√≠nh th·ª©c</strong><br>
                        <a href="https://thaythuoctre.vn" target="_blank" style="color: #fbbf24; text-decoration: none; font-weight: 600;">
                            thaythuoctre.vn
                        </a>
                    </div>
                    <div>
                        <div style="font-size: 24px; margin-bottom: 5px;">ü§ñ</div>
                        <strong style="color: white;">AI Technology</strong><br>
                        <span style="color: #34d399; font-weight: 600;">Google Gemini Pro</span>
                    </div>
                    <div>
                        <div style="font-size: 24px; margin-bottom: 5px;">üìö</div>
                        <strong style="color: white;">Ngu·ªìn d·ªØ li·ªáu</strong><br>
                        <span style="color: #f87171; font-weight: 600;">B·ªô Y t·∫ø Vi·ªát Nam</span>
                    </div>
                </div>
            </div>
        </div>
        """)
        
        # MAIN INTERFACE
        with gr.Row():
            with gr.Column(scale=2):
                question_input = gr.Textbox(
                    lines=4,
                    placeholder="üí¨ ƒê·∫∑t c√¢u h·ªèi v·ªÅ: tri·ªáu ch·ª©ng b·ªánh, thu·ªëc men, ch·∫ø ƒë·ªô dinh d∆∞·ª°ng, s∆° c·ª©u, ph√≤ng b·ªánh, x√©t nghi·ªám...",
                    label="ü©∫ C√¢u h·ªèi y t·∫ø c·ªßa b·∫°n",
                    max_lines=6,
                    show_label=True,
                    info="H√£y m√¥ t·∫£ chi ti·∫øt tri·ªáu ch·ª©ng ho·∫∑c v·∫•n ƒë·ªÅ s·ª©c kh·ªèe ƒë·ªÉ nh·∫≠n ƒë∆∞·ª£c t∆∞ v·∫•n ch√≠nh x√°c nh·∫•t."
                )
                
                with gr.Row():
                    submit_btn = gr.Button(
                        "üîç T∆∞ v·∫•n v·ªõi Th·∫ßy thu·ªëc AI", 
                        variant="primary", 
                        size="lg",
                        scale=2
                    )
                    clear_btn = gr.Button("üóëÔ∏è X√≥a", variant="secondary", scale=1)
            
            with gr.Column(scale=1):
                gr.HTML(f"""
                <div class="info-card">
                    <div style="text-align: center; margin-bottom: 20px;">
                        <div style="width: 50px; height: 50px; background: white; border-radius: 50%; display: inline-flex; align-items: center; justify-content: center; margin-bottom: 10px; padding: 4px; box-shadow: 0 4px 15px rgba(0,0,0,0.1);">
                            <img src="http://thaythuoctre.vn/wp-content/uploads/2020/12/logo-ttt.png" 
                                 alt="Logo TTT" 
                                 style="width: 100%; height: 100%; object-fit: contain;"
                                 onerror="this.style.display='none'; this.parentElement.innerHTML='üë®‚Äç‚öïÔ∏è';">
                        </div>
                        <h3 style="color: #1e40af; margin: 0; font-size: 18px; font-weight: 700;">
                            H·ªôi Th·∫ßy thu·ªëc tr·∫ª Vi·ªát Nam
                        </h3>
                    </div>
                    
                    <div style="margin-bottom: 20px;">
                        <div style="margin-bottom: 15px;">
                            <strong style="color: #1e40af;">üåê Website:</strong><br>
                            <a href="https://thaythuoctre.vn" target="_blank" style="color: #1d4ed8; text-decoration: none;">
                                thaythuoctre.vn
                            </a>
                        </div>
                        
                        <div style="margin-bottom: 15px;">
                            <strong style="color: #1e40af;">üìß Li√™n h·ªá:</strong><br>
                            <span style="color: #64748b;">info@thaythuoctre.vn</span>
                        </div>
                        
                        <div style="margin-bottom: 15px;">
                            <strong style="color: #1e40af;">üéØ S·ª© m·ªánh:</strong><br>
                            <span style="color: #64748b; font-size: 14px;">
                                N√¢ng cao ch·∫•t l∆∞·ª£ng chƒÉm s√≥c s·ª©c kh·ªèe<br>
                                v√† ·ª©ng d·ª•ng c√¥ng ngh·ªá trong y t·∫ø
                            </span>
                        </div>
                        
                        <div style="background: #f1f5f9; padding: 15px; border-radius: 10px; border-left: 4px solid #1d4ed8; margin-bottom: 15px;">
                            <strong style="color: #1e40af;">üìä Tr·∫°ng th√°i AI:</strong><br>
                            <span style="color: #059669; font-weight: 600;">
                                {initialization_status}
                            </span>
                        </div>
                        
                        <div style="background: #fef3c7; padding: 12px; border-radius: 8px; border-left: 4px solid #f59e0b;">
                            <strong style="color: #92400e;">üîë API Status:</strong><br>
                            <span style="color: #78350f; font-weight: 600;">
                                {"‚úÖ Connected" if GOOGLE_API_KEY != "dummy" else "‚ùå Not configured"}
                            </span>
                        </div>
                    </div>
                    
                    <div class="stat-grid">
                        <div class="stat-item">
                            <div style="font-size: 20px; color: #1d4ed8; font-weight: 700;">24/7</div>
                            <div style="font-size: 12px; color: #64748b;">H·ªó tr·ª£</div>
                        </div>
                        <div class="stat-item">
                            <div style="font-size: 20px; color: #059669; font-weight: 700;">AI</div>
                            <div style="font-size: 12px; color: #64748b;">Th√¥ng minh</div>
                        </div>
                        <div class="stat-item">
                            <div style="font-size: 20px; color: #dc2626; font-weight: 700;">VN</div>
                            <div style="font-size: 12px; color: #64748b;">Ti·∫øng Vi·ªát</div>
                        </div>
                    </div>
                </div>
                """)
        
        # OUTPUT SECTION
        answer_output = gr.Textbox(
            lines=12,
            label="ü©∫ T∆∞ v·∫•n t·ª´ Th·∫ßy thu·ªëc AI",
            show_copy_button=True,
            interactive=False,
            placeholder="C√¢u tr·∫£ l·ªùi chi ti·∫øt t·ª´ AI s·∫Ω hi·ªÉn th·ªã ·ªü ƒë√¢y...",
            info="B·∫°n c√≥ th·ªÉ copy c√¢u tr·∫£ l·ªùi ƒë·ªÉ l∆∞u l·∫°i ho·∫∑c chia s·∫ª v·ªõi Th·∫ßy thu·ªëc."
        )
        
        # EXAMPLES SECTION
        gr.Examples(
            examples=[
                "Tri·ªáu ch·ª©ng c·ªßa b·ªánh ti·ªÉu ƒë∆∞·ªùng type 2 l√† g√¨?",
                "C√°ch ph√≤ng ng·ª´a b·ªánh cao huy·∫øt √°p ·ªü ng∆∞·ªùi tr·∫ª?",
                "Thu·ªëc paracetamol c√≥ t√°c d·ª•ng ph·ª• g√¨? Li·ªÅu d√πng nh∆∞ th·∫ø n√†o?",
                "Ch·∫ø ƒë·ªô ƒÉn u·ªëng cho ng∆∞·ªùi b·ªánh tim m·∫°ch c·∫ßn l∆∞u √Ω g√¨?",
                "C√°ch s∆° c·ª©u ban ƒë·∫ßu khi b·ªã ƒë·ªôt qu·ªµ?",
                "Vaccine COVID-19 c√≥ an to√†n kh√¥ng? Ai n√™n ti√™m?",
                "Tri·ªáu ch·ª©ng vi√™m gan B nh∆∞ th·∫ø n√†o? C√°ch ph√≤ng ng·ª´a?",
                "C√°ch chƒÉm s√≥c tr·∫ª em b·ªã s·ªët cao t·∫°i nh√†?",
                "D·∫•u hi·ªáu nh·∫≠n bi·∫øt b·ªánh tr·∫ßm c·∫£m ·ªü ng∆∞·ªùi tr·∫ª?",
                "Thu·ªëc kh√°ng sinh n√™n d√πng nh∆∞ th·∫ø n√†o cho ƒë√∫ng?",
                "Tri·ªáu ch·ª©ng v√† c√°ch x·ª≠ l√Ω khi b·ªã ng·ªô ƒë·ªôc th·ª±c ph·∫©m?",
                "C√°ch chƒÉm s√≥c da m·∫∑t cho ng∆∞·ªùi b·ªã m·ª•n tr·ª©ng c√°?"
            ],
            inputs=question_input,
            label="üí° C√¢u h·ªèi m·∫´u - Click ƒë·ªÉ th·ª≠ ngay",
            examples_per_page=6
        )
        
        # PROFESSIONAL FOOTER
        gr.HTML("""
        <div style="background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%); padding: 30px; border-radius: 20px; margin-top: 30px; border-top: 4px solid #1d4ed8; text-align: center;">
            <div style="display: flex; align-items: center; justify-content: center; gap: 15px; margin-bottom: 20px; flex-wrap: wrap;">
                <div style="width: 50px; height: 50px; background: white; border-radius: 50%; display: flex; align-items: center; justify-content: center; padding: 4px; box-shadow: 0 4px 15px rgba(0,0,0,0.1);">
                    <img src="http://thaythuoctre.vn/wp-content/uploads/2020/12/logo-ttt.png" 
                         alt="Logo TTT" 
                         style="width: 100%; height: 100%; object-fit: contain;"
                         onerror="this.style.display='none'; this.parentElement.innerHTML='üë®‚Äç‚öïÔ∏è';">
                </div>
                <div>
                    <h4 style="margin: 0; color: #1e40af; font-size: 20px; font-weight: 700;">
                        H·ªôi Th·∫ßy thu·ªëc tr·∫ª Vi·ªát Nam
                    </h4>
                    <p style="margin: 5px 0 0 0; color: #64748b; font-size: 14px;">
                        Vietnam Young Physicians' Association
                    </p>
                </div>
            </div>
            
            <div style="background: white; padding: 20px; border-radius: 15px; margin-bottom: 20px; box-shadow: 0 4px 15px rgba(0,0,0,0.05);">
                <p style="color: #dc2626; margin: 0; font-weight: 600; font-size: 16px;">
                    ‚ö†Ô∏è L∆ØU √ù QUAN TR·ªåNG
                </p>
                <p style="color: #64748b; margin: 10px 0 0 0; line-height: 1.6;">
                    Th√¥ng tin t∆∞ v·∫•n t·ª´ AI ch·ªâ mang t√≠nh ch·∫•t <strong>tham kh·∫£o</strong> v√† <strong>kh√¥ng thay th·∫ø</strong> 
                    cho vi·ªác kh√°m b·ªánh, ch·∫©n ƒëo√°n v√† ƒëi·ªÅu tr·ªã tr·ª±c ti·∫øp t·ª´ Th·∫ßy thu·ªëc.<br>
                    <strong>H√£y ƒë·∫øn c∆° s·ªü y t·∫ø g·∫ßn nh·∫•t</strong> khi c√≥ tri·ªáu ch·ª©ng b·∫•t th∆∞·ªùng ho·∫∑c c·∫ßn h·ªó tr·ª£ y t·∫ø kh·∫©n c·∫•p.<br>
                    <strong>S·ªë ƒëi·ªán tho·∫°i c·∫•p c·ª©u: 115</strong>
                </p>
            </div>
            
            <div style="border-top: 1px solid #e2e8f0; padding-top: 20px; color: #94a3b8; font-size: 13px;">
                <p style="margin: 5px 0;">
                    üîí D·ªØ li·ªáu ƒë∆∞·ª£c b·∫£o m·∫≠t tuy·ªát ƒë·ªëi | üöÄ Powered by Google Gemini AI | üáªüá≥ Made in Vietnam
                </p>
                <p style="margin: 5px 0;">
                    ¬© 2024 H·ªôi Th·∫ßy thu·ªëc tr·∫ª Vi·ªát Nam. Ph√°t tri·ªÉn b·ªüi c√°c Th·∫ßy thu·ªëc tr·∫ª Vi·ªát Nam.
                </p>
                <p style="margin: 10px 0 0 0;">
                    <a href="https://thaythuoctre.vn" target="_blank" style="color: #1d4ed8; text-decoration: none;">
                        üåê Truy c·∫≠p website ch√≠nh th·ª©c
                    </a> | 
                    <a href="mailto:info@thaythuoctre.vn" style="color: #1d4ed8; text-decoration: none;">
                        üìß Li√™n h·ªá h·ªó tr·ª£
                    </a>
                </p>
            </div>
        </div>
        """)
        
        # EVENT HANDLERS
        submit_btn.click(ask_question, inputs=question_input, outputs=answer_output)
        question_input.submit(ask_question, inputs=question_input, outputs=answer_output)
        clear_btn.click(lambda: ("", ""), outputs=[question_input, answer_output])
    
    return interface

# T·∫°o professional interface
print("üé® Creating professional interface...")
interface = create_professional_interface()

# Main execution
if __name__ == "__main__":
    print("\n" + "=" * 60)
    print("üöÄ LAUNCHING HEALTHBOT FOR H·ªòI TH·∫¶Y THU·ªêC TR·∫∫ VI·ªÜT NAM")
    print("=" * 60)
    print(f"üì° Server: 0.0.0.0:{port}")
    print(f"üîë API Key: {'‚úÖ Configured' if GOOGLE_API_KEY != 'dummy' else '‚ùå Missing'}")
    print(f"ü§ñ AI Model: Google Gemini 1.5 Pro")
    print(f"‚ö° Optimizations: Threading timeout + Smart limiting")
    print("=" * 60)
    
    # Start optimized background initialization
    print("üî• Starting optimized initialization...")
    init_thread = threading.Thread(target=initialize_system, daemon=True)
    init_thread.start()
    
    # Small delay for thread to start
    time.sleep(0.5)
    
    # Launch interface
    try:
        print("üåü Launching professional interface...")
        interface.launch(
            server_name="0.0.0.0",
            server_port=port,
            share=False,
            show_error=True,
            show_api=False,
            quiet=False
        )
        
    except Exception as e:
        print(f"‚ùå Primary launch failed: {e}")
        print("üîÑ Attempting fallback launch...")
        
        try:
            interface.launch(
                server_name="0.0.0.0",
                server_port=port
            )
        except Exception as e2:
            print(f"‚ùå Fallback launch failed: {e2}")
            print("üíî Unable to start server. Check configuration and try again.")
            sys.exit(1)
