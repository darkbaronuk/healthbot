import os
import gradio as gr
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Load API key
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")  # Äá»•i tá»« OPENAI_API_KEY
if not GOOGLE_API_KEY:
    raise ValueError("Thiáº¿u GOOGLE_API_KEY")

print("ğŸš€ Khá»Ÿi Ä‘á»™ng Medical Chatbot vá»›i Google Gemini...")

# Load documents
docs = []
data_folder = "data"
if os.path.exists(data_folder):
    print(f"ğŸ“‚ QuÃ©t thÆ° má»¥c {data_folder}...")
    for file in os.listdir(data_folder):
        if file.endswith(".pdf"):
            print(f"ğŸ“„ Äang táº£i: {file}")
            try:
                loader = PyPDFLoader(os.path.join(data_folder, file))
                docs.extend(loader.load())
            except Exception as e:
                print(f"âŒ Lá»—i táº£i {file}: {e}")
    print(f"âœ… ÄÃ£ táº£i {len(docs)} trang tÃ i liá»‡u")
else:
    print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c {data_folder}")

if docs:
    print("âœ‚ï¸ Chia nhá» tÃ i liá»‡u...")
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000, 
        chunk_overlap=200
    )
    chunks = splitter.split_documents(docs)
    print(f"âœ… Chia thÃ nh {len(chunks)} Ä‘oáº¡n")
    
    print("ğŸ”§ Táº¡o embeddings (miá»…n phÃ­)...")
    # DÃ¹ng HuggingFace embeddings thay vÃ¬ OpenAI (miá»…n phÃ­)
    embedding = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    )
    
    print("ğŸ’¾ Táº¡o vector database...")
    vector_db = Chroma.from_documents(
        chunks, 
        embedding, 
        persist_directory="chroma_db"
    )
    
    # Prompt tá»‘i Æ°u cho Gemini
    prompt = PromptTemplate(
        template="""
Báº¡n lÃ  trá»£ lÃ½ y táº¿ chuyÃªn nghiá»‡p cá»§a Bá»™ Y táº¿ Viá»‡t Nam.

TÃ€I LIá»†U THAM KHáº¢O:
{context}

CÃ‚U Há»I: {question}

HÆ¯á»šNG DáºªN TRáº¢ Lá»œI:
- Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t chÃ­nh xÃ¡c, chuyÃªn nghiá»‡p
- Dá»±a chá»§ yáº¿u vÃ o tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p
- Náº¿u khÃ´ng cÃ³ thÃ´ng tin trong tÃ i liá»‡u, hÃ£y nÃ³i rÃµ "ThÃ´ng tin nÃ y chÆ°a cÃ³ trong tÃ i liá»‡u tham kháº£o"
- ÄÆ°a ra lá»i khuyÃªn y táº¿ cáº©n trá»ng vÃ  khuyáº¿n khÃ­ch tham kháº£o bÃ¡c sÄ© khi cáº§n

TRáº¢ Lá»œI:""",
        input_variables=["context", "question"]
    )
    
    print("ğŸ¤– Thiáº¿t láº­p Gemini AI...")
    qa_chain = RetrievalQA.from_chain_type(
        llm=ChatGoogleGenerativeAI(
            model="gemini-1.5-pro",  # Model tá»‘t nháº¥t cá»§a Google
            google_api_key=GOOGLE_API_KEY,
            temperature=0.3,
            max_output_tokens=8192  # Gemini cÃ³ giá»›i háº¡n khÃ¡c
        ),
        retriever=vector_db.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 5}  # Láº¥y 5 Ä‘oáº¡n liÃªn quan nháº¥t
        ),
        chain_type_kwargs={"prompt": prompt},
        return_source_documents=True
    )
    
    def ask(query):
        if not query.strip():
            return "Vui lÃ²ng nháº­p cÃ¢u há»i."
        
        if len(query) > 1000:
            return "CÃ¢u há»i quÃ¡ dÃ i. Vui lÃ²ng rÃºt ngáº¯n dÆ°á»›i 1000 kÃ½ tá»±."
        
        try:
            print(f"ğŸ” Äang xá»­ lÃ½: {query[:50]}...")
            result = qa_chain({"query": query})
            
            # Láº¥y cÃ¢u tráº£ lá»i
            answer = result["result"]
            
            # ThÃªm nguá»“n tÃ i liá»‡u (optional)
            sources = result.get("source_documents", [])
            if sources:
                source_files = set()
                for doc in sources:
                    if "source" in doc.metadata:
                        source_files.add(os.path.basename(doc.metadata["source"]))
                
                if source_files:
                    answer += f"\n\nğŸ“š Nguá»“n tÃ i liá»‡u: {', '.join(source_files)}"
            
            return answer
            
        except Exception as e:
            error_msg = str(e).lower()
            if "quota" in error_msg or "limit" in error_msg:
                return "âš ï¸ ÄÃ£ vÆ°á»£t quÃ¡ giá»›i háº¡n API. Vui lÃ²ng thá»­ láº¡i sau Ã­t phÃºt."
            elif "safety" in error_msg:
                return "âš ï¸ CÃ¢u há»i cÃ³ thá»ƒ chá»©a ná»™i dung nháº¡y cáº£m. Vui lÃ²ng diá»…n Ä‘áº¡t khÃ¡c."
            else:
                return f"âŒ Lá»—i: {str(e)}\nVui lÃ²ng thá»­ láº¡i hoáº·c Ä‘áº·t cÃ¢u há»i khÃ¡c."
else:
    def ask(query):
        return "ğŸ“‹ ChÆ°a cÃ³ tÃ i liá»‡u PDF nÃ o trong thÆ° má»¥c 'data'. Vui lÃ²ng thÃªm file PDF vÃ  khá»Ÿi Ä‘á»™ng láº¡i."

# Láº¥y port tá»« biáº¿n mÃ´i trÆ°á»ng (cho Render/Heroku)
port = int(os.environ.get("PORT", 7860))
print(f"ğŸŒ Khá»Ÿi Ä‘á»™ng server trÃªn port {port}")

# Táº¡o giao diá»‡n Gradio
interface = gr.Interface(
    fn=ask,
    inputs=gr.Textbox(
        lines=3,
        placeholder="VÃ­ dá»¥: Triá»‡u chá»©ng cá»§a bá»‡nh tiá»ƒu Ä‘Æ°á»ng lÃ  gÃ¬?",
        label="ğŸ’¬ CÃ¢u há»i y táº¿ cá»§a báº¡n"
    ),
    outputs=gr.Textbox(
        lines=10,
        label="ğŸ©º Tráº£ lá»i tá»« trá»£ lÃ½ y táº¿",
        show_copy_button=True
    ),
    title="ğŸ¥ Trá»£ lÃ½ Y táº¿ AI - Powered by Google Gemini",
    description="""
    ğŸ¤– Chatbot y táº¿ thÃ´ng minh dá»±a trÃªn tÃ i liá»‡u chÃ­nh thá»©c cá»§a Bá»™ Y táº¿ Viá»‡t Nam
    
    âš ï¸ **LÆ°u Ã½ quan trá»ng:** 
    - ThÃ´ng tin chá»‰ mang tÃ­nh tham kháº£o
    - KhÃ´ng thay tháº¿ cho tÆ° váº¥n y táº¿ chuyÃªn nghiá»‡p
    - HÃ£y tham kháº£o bÃ¡c sÄ© khi cáº§n thiáº¿t
    """,
    examples=[
        "Triá»‡u chá»©ng cá»§a bá»‡nh tiá»ƒu Ä‘Æ°á»ng lÃ  gÃ¬?",
        "CÃ¡ch phÃ²ng ngá»«a bá»‡nh cao huyáº¿t Ã¡p?",
        "Thuá»‘c nÃ o Ä‘iá»u trá»‹ viÃªm há»ng?",
        "Cháº¿ Ä‘á»™ Äƒn cho ngÆ°á»i bá»‡nh tim máº¡ch?"
    ],
    theme=gr.themes.Soft(),
    allow_flagging="never"
)

# Khá»Ÿi Ä‘á»™ng á»©ng dá»¥ng
print("âœ… Medical Chatbot sáºµn sÃ ng!")
interface.launch(
    server_name="0.0.0.0",
    server_port=port,
    share=False,
    show_error=True,
    quiet=True
)
