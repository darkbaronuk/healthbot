import os
import sys
import gradio as gr
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
import shutil
import threading
import time

# Setup port
port = int(os.environ.get("PORT", 7860))
print(f"ğŸ” ENV PORT: {os.environ.get('PORT', 'Not set')}")
print(f"ğŸ” Using port: {port}")

# Load environment variables
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    print("âŒ GOOGLE_API_KEY chÆ°a Ä‘Æ°á»£c thiáº¿t láº­p!")
    GOOGLE_API_KEY = "dummy"

print("ğŸš€ Khá»Ÿi Ä‘á»™ng Medical Chatbot vá»›i Google Gemini...")

# Global variables
qa_chain = None
vector_db = None
initialization_status = "âš™ï¸ Äang khá»Ÿi táº¡o..."
system_ready = False

def initialize_system():
    """Khá»Ÿi táº¡o há»‡ thá»‘ng AI"""
    global qa_chain, vector_db, initialization_status, system_ready
    
    print("ğŸ”„ FORCE INIT: Starting system initialization...")
    initialization_status = "ğŸ“‚ Äang quÃ©t thÆ° má»¥c PDF..."
    
    try:
        # Clean old ChromaDB
        chroma_path = "chroma_db"
        if os.path.exists(chroma_path):
            print("ğŸ§¹ Cleaning old ChromaDB...")
            shutil.rmtree(chroma_path)
            print("âœ… Old database cleaned")
        
        # Load documents
        docs = []
        data_folder = "data"
        initialization_status = "ğŸ“„ Äang táº£i PDF files..."
        
        if os.path.exists(data_folder):
            print(f"ğŸ“‚ QuÃ©t thÆ° má»¥c {data_folder}...")
            pdf_files = [f for f in os.listdir(data_folder) if f.endswith(".pdf")]
            
            if pdf_files:
                for file in pdf_files:
                    print(f"ğŸ“„ Äang táº£i: {file}")
                    try:
                        loader = PyPDFLoader(os.path.join(data_folder, file))
                        file_docs = loader.load()
                        for doc in file_docs:
                            doc.metadata["source_file"] = file
                        docs.extend(file_docs)
                        print(f"   âœ… ThÃ nh cÃ´ng: {len(file_docs)} trang")
                    except Exception as e:
                        print(f"   âŒ Lá»—i táº£i {file}: {e}")
                        
                print(f"âœ… Tá»•ng cá»™ng: {len(docs)} trang tá»« {len(pdf_files)} file")
            else:
                print(f"âš ï¸ KhÃ´ng cÃ³ file PDF trong {data_folder}")
                initialization_status = "âš ï¸ KhÃ´ng tÃ¬m tháº¥y PDF files"
                return False
        else:
            print(f"âš ï¸ ThÆ° má»¥c {data_folder} khÃ´ng tá»“n táº¡i")
            initialization_status = "âš ï¸ ThÆ° má»¥c data khÃ´ng tá»“n táº¡i"
            return False
        
        if docs and GOOGLE_API_KEY != "dummy":
            initialization_status = "âœ‚ï¸ Äang chia nhá» tÃ i liá»‡u..."
            print("âœ‚ï¸ Chia nhá» tÃ i liá»‡u...")
            splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000, 
                chunk_overlap=200
            )
            chunks = splitter.split_documents(docs)
            print(f"âœ… Chia thÃ nh {len(chunks)} Ä‘oáº¡n")
            
            initialization_status = "ğŸ”§ Äang táº¡o embeddings..."
            print("ğŸ”§ Táº¡o embeddings...")
            embedding = HuggingFaceEmbeddings(
                model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
            
            initialization_status = "ğŸ’¾ Äang táº¡o vector database..."
            print("ğŸ’¾ Táº¡o vector database...")
            try:
                vector_db = Chroma.from_documents(
                    chunks, 
                    embedding, 
                    persist_directory=None
                )
                print("âœ… Vector database created successfully")
            except Exception as e:
                print(f"âŒ ChromaDB error: {e}")
                initialization_status = f"âŒ Lá»—i ChromaDB: {str(e)[:50]}..."
                return False
            
            initialization_status = "ğŸ¤– Äang thiáº¿t láº­p Gemini AI..."
            print("ğŸ¤– Thiáº¿t láº­p Gemini AI...")
            
            prompt = PromptTemplate(
                template="""
Báº¡n lÃ  trá»£ lÃ½ y táº¿ chuyÃªn nghiá»‡p cá»§a Bá»™ Y táº¿ Viá»‡t Nam.

TÃ€I LIá»†U THAM KHáº¢O:
{context}

CÃ‚U Há»I: {question}

HÆ¯á»šNG DáºªN TRáº¢ Lá»œI:
- Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t chÃ­nh xÃ¡c, chuyÃªn nghiá»‡p
- Dá»±a chá»§ yáº¿u vÃ o tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p
- Náº¿u khÃ´ng cÃ³ thÃ´ng tin trong tÃ i liá»‡u, hÃ£y nÃ³i rÃµ "ThÃ´ng tin nÃ y chÆ°a cÃ³ trong tÃ i liá»‡u tham kháº£o"
- ÄÆ°a ra lá»i khuyÃªn y táº¿ cáº©n trá»ng vÃ  khuyáº¿n khÃ­ch tham kháº£o bÃ¡c sÄ© khi cáº§n

TRáº¢ Lá»œI:""",
                input_variables=["context", "question"]
            )
            
            llm = ChatGoogleGenerativeAI(
                model="gemini-1.5-pro",
                google_api_key=GOOGLE_API_KEY,
                temperature=0.3,
                max_output_tokens=8192
            )
            
            qa_chain = RetrievalQA.from_chain_type(
                llm=llm,
                retriever=vector_db.as_retriever(
                    search_type="similarity",
                    search_kwargs={"k": 5}
                ),
                chain_type_kwargs={"prompt": prompt},
                return_source_documents=True
            )
            
            print("âœ… Há»‡ thá»‘ng AI Ä‘Ã£ sáºµn sÃ ng!")
            initialization_status = "âœ… Sáºµn sÃ ng tráº£ lá»i cÃ¢u há»i!"
            system_ready = True
            return True
        else:
            print("âš ï¸ KhÃ´ng cÃ³ tÃ i liá»‡u hoáº·c API key khÃ´ng há»£p lá»‡")
            initialization_status = "âš ï¸ API key khÃ´ng há»£p lá»‡"
            return False
            
    except Exception as e:
        print(f"âŒ Lá»—i khá»Ÿi táº¡o há»‡ thá»‘ng: {e}")
        initialization_status = f"âŒ Lá»—i: {str(e)[:100]}..."
        import traceback
        traceback.print_exc()
        return False

def ask_question(query):
    """Xá»­ lÃ½ cÃ¢u há»i tá»« ngÆ°á»i dÃ¹ng"""
    global initialization_status, system_ready
    
    if not query.strip():
        return f"â“ Vui lÃ²ng nháº­p cÃ¢u há»i.\n\nğŸ“Š Tráº¡ng thÃ¡i: {initialization_status}"
    
    if len(query) > 1000:
        return "ğŸ“ CÃ¢u há»i quÃ¡ dÃ i. Vui lÃ²ng rÃºt ngáº¯n dÆ°á»›i 1000 kÃ½ tá»±."
    
    if GOOGLE_API_KEY == "dummy":
        return "âš™ï¸ Há»‡ thá»‘ng chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh Ä‘Ãºng. Vui lÃ²ng kiá»ƒm tra GOOGLE_API_KEY."
    
    if not system_ready or not qa_chain:
        return f"""ğŸ”§ Há»‡ thá»‘ng AI chÆ°a sáºµn sÃ ng.

ğŸ“Š Tráº¡ng thÃ¡i hiá»‡n táº¡i: {initialization_status}

ğŸ’¡ Vui lÃ²ng chá» 2-3 phÃºt Ä‘á»ƒ system:
   â€¢ Load file PDF (36 trang)
   â€¢ Táº¡o vector database 
   â€¢ Khá»Ÿi táº¡o AI model

ğŸ”„ Thá»­ láº¡i sau Ã­t phÃºt..."""
    
    try:
        print(f"ğŸ” Xá»­ lÃ½ cÃ¢u há»i: {query[:50]}...")
        result = qa_chain({"query": query})
        
        answer = result["result"]
        
        # ThÃªm thÃ´ng tin nguá»“n
        sources = result.get("source_documents", [])
        if sources:
            source_files = set()
            for doc in sources:
                if "source_file" in doc.metadata:
                    source_files.add(doc.metadata["source_file"])
            
            if source_files:
                answer += f"\n\nğŸ“š Nguá»“n tÃ i liá»‡u: {', '.join(source_files)}"
        
        return answer
        
    except Exception as e:
        error_msg = str(e).lower()
        if "quota" in error_msg or "limit" in error_msg:
            return "âš ï¸ ÄÃ£ vÆ°á»£t quÃ¡ giá»›i háº¡n API (15 requests/phÃºt). Vui lÃ²ng chá» vÃ  thá»­ láº¡i sau."
        elif "safety" in error_msg:
            return "âš ï¸ CÃ¢u há»i cÃ³ thá»ƒ chá»©a ná»™i dung nháº¡y cáº£m. Vui lÃ²ng diá»…n Ä‘áº¡t láº¡i cÃ¢u há»i."
        elif "api" in error_msg or "key" in error_msg:
            return "ğŸ”‘ Lá»—i API Key. Vui lÃ²ng kiá»ƒm tra cáº¥u hÃ¬nh GOOGLE_API_KEY."
        else:
            return f"âŒ Lá»—i: {str(e)}\n\nğŸ’¡ Vui lÃ²ng thá»­ láº¡i hoáº·c Ä‘áº·t cÃ¢u há»i khÃ¡c."

# Táº¡o giao diá»‡n Gradio
print("ğŸ¨ Táº¡o giao diá»‡n Gradio...")
interface = gr.Interface(
    fn=ask_question,
    inputs=gr.Textbox(
        lines=3,
        placeholder="VÃ­ dá»¥: Triá»‡u chá»©ng cá»§a bá»‡nh tiá»ƒu Ä‘Æ°á»ng lÃ  gÃ¬?",
        label="ğŸ’¬ CÃ¢u há»i y táº¿ cá»§a báº¡n",
        max_lines=5
    ),
    outputs=gr.Textbox(
        lines=10,
        label="ğŸ©º Tráº£ lá»i tá»« trá»£ lÃ½ y táº¿",
        show_copy_button=True
    ),
    title="ğŸ¥ Trá»£ lÃ½ Y táº¿ AI - Powered by Google Gemini",
    description="""
    ğŸ¤– **Chatbot y táº¿ thÃ´ng minh** dá»±a trÃªn tÃ i liá»‡u chÃ­nh thá»©c cá»§a Bá»™ Y táº¿ Viá»‡t Nam
    
    ğŸ“Š **Tráº¡ng thÃ¡i há»‡ thá»‘ng:** âš™ï¸ Äang khá»Ÿi táº¡o...
    
    âš ï¸ **LÆ°u Ã½ quan trá»ng:** 
    - ThÃ´ng tin chá»‰ mang tÃ­nh tham kháº£o
    - KhÃ´ng thay tháº¿ cho tÆ° váº¥n y táº¿ chuyÃªn nghiá»‡p  
    - HÃ£y tham kháº£o bÃ¡c sÄ© khi cáº§n thiáº¿t
    - Giá»›i háº¡n: 15 cÃ¢u há»i/phÃºt (API miá»…n phÃ­)
    """,
    examples=[
        "Triá»‡u chá»©ng cá»§a bá»‡nh tiá»ƒu Ä‘Æ°á»ng lÃ  gÃ¬?",
        "CÃ¡ch phÃ²ng ngá»«a bá»‡nh cao huyáº¿t Ã¡p?", 
        "Thuá»‘c nÃ o Ä‘iá»u trá»‹ viÃªm há»ng?",
        "Cháº¿ Ä‘á»™ Äƒn cho ngÆ°á»i bá»‡nh tim máº¡ch?",
        "CÃ¡ch sÆ¡ cá»©u khi bá»‹ Ä‘á»™t quá»µ?"
    ],
    theme=gr.themes.Soft(),
    allow_flagging="never"
)

if __name__ == "__main__":
    print(f"ğŸš€ Launching Gradio on port {port}")
    print(f"ğŸ“¡ Server binding: 0.0.0.0:{port}")
    
    # FORCE start initialization BEFORE launch
    print("ğŸ”¥ STARTING FORCED INITIALIZATION...")
    init_thread = threading.Thread(target=initialize_system)
    init_thread.daemon = True
    init_thread.start()
    
    # Small delay Ä‘á»ƒ thread báº¯t Ä‘áº§u
    time.sleep(0.5)
    
    try:
        interface.launch(
            server_name="0.0.0.0",
            server_port=port,
            share=False,
            show_error=True
        )
    except Exception as e:
        print(f"âŒ Launch failed: {e}")
        try:
            interface.launch(
                server_name="0.0.0.0",
                server_port=port
            )
        except Exception as e2:
            print(f"âŒ Second launch failed: {e2}")
            sys.exit(1)
