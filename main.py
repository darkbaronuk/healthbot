import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from tqdm import tqdm

# 1. Load API Key
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")  # Äá»•i tá»« OPENAI_API_KEY
if not api_key:
    print("âŒ GOOGLE_API_KEY chÆ°a Ä‘Æ°á»£c thiáº¿t láº­p!")
    print("ğŸ”‘ HÆ°á»›ng dáº«n láº¥y key: https://makersuite.google.com/app/apikey")
    exit()

print("âœ… Google API Key Ä‘Ã£ Ä‘Æ°á»£c táº£i")

# 2. Tá»± Ä‘á»™ng náº¡p toÃ n bá»™ PDF tá»« thÆ° má»¥c /data
pdf_folder = "data"
all_docs = []
print(f"ğŸ“‚ Äang quÃ©t file PDF trong thÆ° má»¥c: {pdf_folder}")

if not os.path.exists(pdf_folder):
    print(f"âŒ ThÆ° má»¥c {pdf_folder} khÃ´ng tá»“n táº¡i!")
    print(f"ğŸ“ Táº¡o thÆ° má»¥c {pdf_folder} vÃ  thÃªm file PDF vÃ o Ä‘Ã³")
    os.makedirs(pdf_folder)
    exit()

pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith(".pdf")]
if not pdf_files:
    print(f"âŒ KhÃ´ng cÃ³ file PDF nÃ o trong thÆ° má»¥c {pdf_folder}")
    print("ğŸ“„ Vui lÃ²ng thÃªm file PDF vÃ o thÆ° má»¥c data/")
    exit()

for filename in pdf_files:
    file_path = os.path.join(pdf_folder, filename)
    print(f"ğŸ“„ Äang náº¡p: {filename}")
    try:
        loader = PyPDFLoader(file_path)
        docs = loader.load()
        for doc in docs:
            doc.metadata["source_file"] = filename
        all_docs.extend(docs)
        print(f"   âœ… ThÃ nh cÃ´ng: {len(docs)} trang")
    except Exception as e:
        print(f"   âŒ Lá»—i: {e}")

print(f"âœ… Tá»•ng cá»™ng Ä‘Ã£ náº¡p {len(all_docs)} trang tá»« {len(pdf_files)} file PDF.")

if not all_docs:
    print("âŒ KhÃ´ng cÃ³ tÃ i liá»‡u nÃ o Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng!")
    exit()

# 3. Cáº¯t nhá» tÃ i liá»‡u
print("âœ‚ï¸ Äang chia nhá» tÃ i liá»‡u...")
splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000, 
    chunk_overlap=200,
    separators=["\n\n", "\n", ". ", " ", ""]
)
chunks = splitter.split_documents(all_docs)
print(f"âœ… ÄÃ£ chia thÃ nh {len(chunks)} Ä‘oáº¡n vÄƒn báº£n.")

# 4. Táº¡o vector database vá»›i HuggingFace embeddings (miá»…n phÃ­)
print("ğŸ”§ Äang táº£i mÃ´ hÃ¬nh embedding (láº§n Ä‘áº§u cÃ³ thá»ƒ máº¥t vÃ i phÃºt)...")
embedding = HuggingFaceEmbeddings(
    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    model_kwargs={'device': 'cpu'},
    encode_kwargs={'normalize_embeddings': True}
)

print("ğŸ’¾ Äang táº¡o vector database...")
# Kiá»ƒm tra xem Ä‘Ã£ cÃ³ database chÆ°a
if os.path.exists("chroma_db") and os.listdir("chroma_db"):
    print("ğŸ“‚ TÃ¬m tháº¥y database cÅ©, Ä‘ang táº£i...")
    vector_db = Chroma(
        embedding_function=embedding, 
        persist_directory="chroma_db"
    )
    print("âœ… ÄÃ£ táº£i database cÃ³ sáºµn")
else:
    print("ğŸ†• Táº¡o database má»›i...")
    vector_db = Chroma(
        embedding_function=embedding, 
        persist_directory="chroma_db"
    )
    
    # ThÃªm tá»«ng batch Ä‘á»ƒ trÃ¡nh lá»—i memory
    batch_size = 50
    for i in tqdm(range(0, len(chunks), batch_size), desc="Äang vector hÃ³a"):
        batch = chunks[i:i + batch_size]
        vector_db.add_documents(batch)
    
    vector_db.persist()
    print("âœ… ÄÃ£ lÆ°u vector database vÃ o thÆ° má»¥c chroma_db/")

# 5. Táº¡o prompt tiáº¿ng Viá»‡t chuyÃªn ngÃ nh y táº¿ cho Gemini
custom_prompt = PromptTemplate(
    template="""
Báº¡n lÃ  trá»£ lÃ½ y táº¿ chuyÃªn nghiá»‡p cá»§a Bá»™ Y táº¿ Viá»‡t Nam. HÃ£y tráº£ lá»i dá»±a trÃªn cÃ¡c tÃ i liá»‡u chÃ­nh thá»©c.

TÃ€I LIá»†U THAM KHáº¢O:
{context}

CÃ‚U Há»I: {question}

HÆ¯á»šNG DáºªN TRáº¢ Lá»œI:
- Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t chÃ­nh xÃ¡c, chuyÃªn nghiá»‡p
- Dá»±a chá»§ yáº¿u vÃ o thÃ´ng tin trong tÃ i liá»‡u
- Náº¿u khÃ´ng cÃ³ thÃ´ng tin cá»¥ thá»ƒ, hÃ£y nÃ³i rÃµ "ThÃ´ng tin nÃ y chÆ°a cÃ³ trong tÃ i liá»‡u"
- LuÃ´n khuyáº¿n khÃ­ch tham kháº£o Ã½ kiáº¿n bÃ¡c sÄ© chuyÃªn khoa khi cáº§n thiáº¿t
- ÄÆ°a ra thÃ´ng tin y táº¿ cáº©n trá»ng vÃ  cÃ³ trÃ¡ch nhiá»‡m

TRáº¢ Lá»œI:""",
    input_variables=["context", "question"]
)

# 6. Táº¡o mÃ´ hÃ¬nh há»i Ä‘Ã¡p vá»›i Google Gemini
print("ğŸ¤– Äang khá»Ÿi táº¡o Google Gemini...")
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-pro",  # Model tá»‘t nháº¥t hiá»‡n táº¡i
    google_api_key=api_key,
    temperature=0.3,  # Giáº£m tÃ­nh ngáº«u nhiÃªn cho cÃ¢u tráº£ lá»i y táº¿
    max_output_tokens=8192,
    safety_settings={
        "HARM_CATEGORY_DANGEROUS_CONTENT": "BLOCK_NONE",
        "HARM_CATEGORY_SEXUALLY_EXPLICIT": "BLOCK_NONE", 
        "HARM_CATEGORY_HATE_SPEECH": "BLOCK_NONE",
        "HARM_CATEGORY_HARASSMENT": "BLOCK_NONE"
    }
)

retriever = vector_db.as_retriever(
    search_type="similarity", 
    search_kwargs={"k": 5}  # Láº¥y 5 Ä‘oáº¡n liÃªn quan nháº¥t
)

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=True,
    chain_type_kwargs={"prompt": custom_prompt}
)

print("âœ… Há»‡ thá»‘ng Ä‘Ã£ sáºµn sÃ ng!")

# 7. Giao diá»‡n há»i Ä‘Ã¡p vá»›i error handling
def ask_question(query):
    """Xá»­ lÃ½ cÃ¢u há»i vá»›i error handling"""
    try:
        result = qa_chain({"query": query})
        answer = result["result"]
        
        # ThÃªm thÃ´ng tin nguá»“n
        sources = result.get("source_documents", [])
        if sources:
            source_files = set()
            for doc in sources:
                source_file = doc.metadata.get("source_file", "Unknown")
                source_files.add(source_file)
            
            if source_files:
                answer += f"\n\nğŸ“š Nguá»“n tÃ i liá»‡u: {', '.join(source_files)}"
        
        return answer
        
    except Exception as e:
        error_msg = str(e).lower()
        if "quota" in error_msg or "limit" in error_msg:
            return "âš ï¸ ÄÃ£ vÆ°á»£t quÃ¡ giá»›i háº¡n API (15 requests/phÃºt). Vui lÃ²ng chá» vÃ  thá»­ láº¡i."
        elif "safety" in error_msg:
            return "âš ï¸ CÃ¢u há»i cÃ³ thá»ƒ chá»©a ná»™i dung nháº¡y cáº£m. Vui lÃ²ng diá»…n Ä‘áº¡t láº¡i."
        else:
            return f"âŒ Lá»—i: {str(e)}\nVui lÃ²ng thá»­ láº¡i hoáº·c Ä‘áº·t cÃ¢u há»i khÃ¡c."

# 8. VÃ²ng láº·p há»i Ä‘Ã¡p
print("\n" + "="*60)
print("ğŸ¥ TRá»¢ LÃ Y Táº¾ AI - POWERED BY GOOGLE GEMINI")
print("="*60)
print("ğŸ’¡ Máº¹o sá»­ dá»¥ng:")
print("   - Äáº·t cÃ¢u há»i cá»¥ thá»ƒ vá» y táº¿")
print("   - CÃ³ thá»ƒ há»i vá» triá»‡u chá»©ng, Ä‘iá»u trá»‹, phÃ²ng ngá»«a")
print("   - GÃµ 'exit', 'quit' hoáº·c 'thoÃ¡t' Ä‘á»ƒ káº¿t thÃºc")
print("   - Giá»›i háº¡n: 15 cÃ¢u há»i/phÃºt")
print("\nâš ï¸  LÆ¯U Ã: ThÃ´ng tin chá»‰ mang tÃ­nh tham kháº£o, khÃ´ng thay tháº¿ tÆ° váº¥n y táº¿ chuyÃªn nghiá»‡p!")
print("="*60)

question_count = 0
while True:
    try:
        query = input(f"\nğŸ§‘ CÃ¢u há»i #{question_count + 1}: ").strip()
        
        if query.lower() in ["exit", "quit", "thoÃ¡t", "q"]:
            print("ğŸ‘‹ Cáº£m Æ¡n báº¡n Ä‘Ã£ sá»­ dá»¥ng Trá»£ lÃ½ Y táº¿ AI!")
            break
        
        if not query:
            print("âŒ Vui lÃ²ng nháº­p cÃ¢u há»i.")
            continue
            
        if len(query) > 1000:
            print("âŒ CÃ¢u há»i quÃ¡ dÃ i. Vui lÃ²ng rÃºt ngáº¯n dÆ°á»›i 1000 kÃ½ tá»±.")
            continue
        
        print(f"\nğŸ” Äang tÃ¬m kiáº¿m thÃ´ng tin liÃªn quan...")
        answer = ask_question(query)
        
        print("\nğŸ©º TRáº¢ Lá»œI:")
        print("-" * 50)
        print(answer)
        print("-" * 50)
        
        question_count += 1
        
        # Cáº£nh bÃ¡o giá»›i háº¡n API
        if question_count % 10 == 0:
            print(f"\nğŸ’¡ Báº¡n Ä‘Ã£ há»i {question_count} cÃ¢u. Nhá»› giá»›i háº¡n 15 cÃ¢u/phÃºt cá»§a Gemini API.")
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ÄÃ£ dá»«ng chÆ°Æ¡ng trÃ¬nh. Cáº£m Æ¡n báº¡n!")
        break
    except Exception as e:
        print(f"\nâŒ Lá»—i khÃ´ng mong muá»‘n: {e}")
        print("ğŸ”„ Vui lÃ²ng thá»­ láº¡i...")

print("\nğŸ”š ChÆ°Æ¡ng trÃ¬nh káº¿t thÃºc.")
