import os
from dotenv import load_dotenv

from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.document_loaders import UnstructuredPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# 1. Load API Key
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    print("âŒ OPENAI_API_KEY chÆ°a Ä‘Æ°á»£c thiáº¿t láº­p!")
    exit()

# 2. Tá»± Ä‘á»™ng náº¡p toÃ n bá»™ PDF tá»« thÆ° má»¥c /data
pdf_folder = "data"
all_docs = []

print(f"ğŸ“‚ Äang quÃ©t file PDF trong thÆ° má»¥c: {pdf_folder}")
for filename in os.listdir(pdf_folder):
    if filename.endswith(".pdf"):
        file_path = os.path.join(pdf_folder, filename)
        print(f"ğŸ“„ Náº¡p: {filename}")
        loader = UnstructuredPDFLoader(file_path)
        docs = loader.load()
        for doc in docs:
            doc.metadata["source_file"] = filename
        all_docs.extend(docs)

print(f"âœ… ÄÃ£ náº¡p {len(all_docs)} trang tÃ i liá»‡u tá»« {len(os.listdir(pdf_folder))} file.")

# 3. Cáº¯t nhá» tÃ i liá»‡u
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = splitter.split_documents(all_docs)
print(f"âœ‚ï¸ ÄÃ£ chia thÃ nh {len(chunks)} Ä‘oáº¡n vÄƒn báº£n.")

# 4. Táº¡o vector database (Chroma)
embedding = OpenAIEmbeddings()
from tqdm import tqdm  # hiá»ƒn thá»‹ tiáº¿n trÃ¬nh

vector_db = Chroma(embedding_function=embedding, persist_directory="chroma_db")

# ThÃªm tá»«ng batch nhá» (vd: má»—i batch 50 Ä‘oáº¡n)
batch_size = 50
for i in tqdm(range(0, len(chunks), batch_size), desc="Äang táº¡o vector"):
    batch = chunks[i:i + batch_size]
    vector_db.add_documents(batch)

vector_db.persist()
print("âœ… ÄÃ£ lÆ°u vector hÃ³a vÃ o thÆ° má»¥c chroma_db/")

# 5. Táº¡o prompt tiáº¿ng Viá»‡t chuyÃªn ngÃ nh y táº¿
custom_prompt = PromptTemplate(
    template="""
Báº¡n lÃ  trá»£ lÃ½ y táº¿ thÃ´ng minh. HÃ£y tráº£ lá»i dá»±a trÃªn hÆ°á»›ng dáº«n chÃ­nh thá»©c cá»§a Bá»™ Y táº¿ Viá»‡t Nam.

DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c tÃ i liá»‡u tham kháº£o:

{context}

CÃ¢u há»i: {question}

Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, ngáº¯n gá»n, chÃ­nh xÃ¡c theo chuyÃªn mÃ´n y táº¿. Náº¿u khÃ´ng cháº¯c cháº¯n, hÃ£y nÃ³i rÃµ chÆ°a cÃ³ Ä‘á»§ thÃ´ng tin.""",
    input_variables=["context", "question"]
)

# 6. Táº¡o mÃ´ hÃ¬nh há»i Ä‘Ã¡p
llm = ChatOpenAI(model_name="gpt-4", temperature=0)
retriever = vector_db.as_retriever(search_type="similarity", search_kwargs={"k": 4})

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=True,
    chain_type_kwargs={"prompt": custom_prompt}
)

# 7. Giao diá»‡n há»i Ä‘Ã¡p cÆ¡ báº£n
print("\nğŸš‘ Chatbot Y táº¿ sáºµn sÃ ng! GÃµ 'exit' Ä‘á»ƒ thoÃ¡t.\n")
while True:
    query = input("ğŸ§‘ Báº¡n há»i: ")
    if query.strip().lower() in ["exit", "quit", "thoÃ¡t"]:
        break
    result = qa_chain({"query": query})
    print("\nğŸ¤– Trá»£ lÃ½ y táº¿ tráº£ lá»i:\n", result["result"])
    print("-" * 60)

